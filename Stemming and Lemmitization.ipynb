{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9ee17e2",
   "metadata": {},
   "source": [
    "Lemmatization in Python\n",
    "-\n",
    "Lemmatization deals with reducing the word or the search query to its canonical dictionary form. The root word is called a ‘lemma’ and the method is called lemmatization. This approach takes a part of the word into consideration in a way that it is recognized as a single element. The NLTK Lemmatization method is based on WorldNet’s built-in morph function. Text preprocessing includes both stemming as well as lemmatization. Many people find the two terms confusing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6c0b1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e313afeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemma for studies is study\n",
      "Lemma for studying is studying\n",
      "Lemma for cries is cry\n",
      "Lemma for cry is cry\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import \tWordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "text = \"studies studying cries cry\"\n",
    "tokenization = nltk.word_tokenize(text)\n",
    "for w in tokenization:\n",
    "    print(\"Lemma for {} is {}\".format(w, wordnet_lemmatizer.lemmatize(w))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ac7a22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be7a2ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The  :  The\n",
      "NLTK  :  NLTK\n",
      "Lemmatization  :  Lemmatization\n",
      "method  :  method\n",
      "is  :  is\n",
      "based  :  based\n",
      "on  :  on\n",
      "WorldNet  :  WorldNet\n",
      "’  :  ’\n",
      "s  :  s\n",
      "built-in  :  built-in\n",
      "morph  :  morph\n",
      "function  :  function\n",
      ".  :  .\n",
      "Text  :  Text\n",
      "preprocessing  :  preprocessing\n",
      "includes  :  includes\n",
      "both  :  both\n",
      "stemming  :  stemming\n",
      "as  :  a\n",
      "well  :  well\n",
      "as  :  a\n",
      "lemmatization  :  lemmatization\n",
      ".  :  .\n",
      "The  :  The\n",
      "cries  :  cry\n",
      "is  :  is\n",
      "not  :  not\n",
      "good  :  good\n",
      ".  :  .\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import \tWordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "new_text = \"The NLTK Lemmatization method is based on WorldNet’s built-in morph function. Text preprocessing includes both stemming as well as lemmatization. The cries is not good.\"\n",
    "words = word_tokenize(new_text)\n",
    "\n",
    "for w in words:\n",
    "    print(w,\" : \",  wordnet_lemmatizer.lemmatize(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68687a96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f8f5bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eb4592b6",
   "metadata": {},
   "source": [
    "# Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fb6fad",
   "metadata": {},
   "source": [
    "stemming is a rule-based text normalization technique that reduces the prefix and suffix of the word to its root form. However, stemming is a faster process compared to lemmatization as it does not consider the context of the words.\n",
    "It is a technique in which a set of words in a sentence are converted into a sequence to shorten its lookup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c01a7c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a703afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n",
      "rana\n",
      "saeed\n",
      ",\n",
      "you\n",
      "have\n",
      "to\n",
      "build\n",
      "a\n",
      "veri\n",
      "good\n",
      "site\n",
      "and\n",
      "i\n",
      "love\n",
      "visit\n",
      "your\n",
      "site\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "sentence=\"Hello Rana Saeed, You have to build a very good site and I love visiting your site.\"\n",
    "words = word_tokenize(sentence)\n",
    "ps = PorterStemmer()\n",
    "for w in words:\n",
    "    rootWord=ps.stem(w)\n",
    "    print(rootWord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679d7729",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f0a503aa",
   "metadata": {},
   "source": [
    "# temming words using NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e169cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "program  :  program\n",
      "programs  :  program\n",
      "programmer  :  programm\n",
      "programming  :  program\n",
      "programmers  :  programm\n"
     ]
    }
   ],
   "source": [
    "# import these modules\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "ps = PorterStemmer()\n",
    "\n",
    "# choose some words to be stemmed\n",
    "words = [\"program\", \"programs\", \"programmer\", \"programming\", \"programmers\"]\n",
    "\n",
    "for w in words:\n",
    "\tprint(w, \" : \", ps.stem(w))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462a11f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "343a30b6",
   "metadata": {},
   "source": [
    "# Stemming words from sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a8519ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Programmers  :  programm\n",
      "program  :  program\n",
      "with  :  with\n",
      "programming  :  program\n",
      "languages  :  languag\n"
     ]
    }
   ],
   "source": [
    "# importing modules\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "ps = PorterStemmer()\n",
    "\n",
    "sentence = \"Programmers program with programming languages\"\n",
    "words = word_tokenize(sentence)\n",
    "\n",
    "for w in words:\n",
    "\tprint(w, \" : \", ps.stem(w))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a72f43d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf01bea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
